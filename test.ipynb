{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`, save it as numpy.ndarray\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "class MnistDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index].reshape(28, 28).astype(np.uint8)\n",
    "        y = torch.tensor(self.targets[index])\n",
    "        x = self.transform(x).squeeze()\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fee660f6d30>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fee704bff40>\n"
     ]
    }
   ],
   "source": [
    "from source import dataset\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "train_loader, test_loader = dataset.get_mnist_data(device, train_batch_size=10, test_batch_size=10)\n",
    "# print(train_dataset[0])\n",
    "print(train_loader)\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 28, 28])\n",
      "torch.Size([10])\n",
      "0 [tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), tensor([6, 3, 8, 7, 3, 0, 5, 0, 2, 7], dtype=torch.uint8)]\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    if i >= 1:\n",
    "        break\n",
    "    print(data[0].shape)\n",
    "    print(data[1].shape)\n",
    "    print(i, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5, dtype=torch.uint8)\n",
      "torch.Size([28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_images, train_labels = load_mnist('data/MNIST', kind='train')  # ndarray, each row is an image\n",
    "test_images, test_labels = load_mnist('data/MNIST', kind='t10k')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = MnistDataset(train_images, train_labels, transform=transform)   # pytorch dataset class, indexed by []\n",
    "test_dataset = MnistDataset(test_images, test_labels, transform=transform)\n",
    "\n",
    "toshow = test_dataset[102][0]\n",
    "label = test_dataset[102][1]\n",
    "print(label)\n",
    "print(toshow.shape)\n",
    "plt.imshow(toshow.numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1%50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
